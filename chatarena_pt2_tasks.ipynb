{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Project Overview** \n",
    "As the capabilities of Large Language Models (LLMs) continue to grow, evaluating their performance has become more important than ever, especially in the face of the biases that can be embedded in them [1]. Human evaluation of LLMs is crucial, yet poses a variety of challenges due to the inherently subjective nature of human assessments. What one user considers to be a “good” response may not be perceived as such by another user, leading to inconsistent feedback of LLM performance [2]. Additionally, there is currently no “standard” methodology or consensus on best practices for the human evaluation of LLMs, making it challenging to compare different research results studying their performance [3]. Ultimately, these factors make it difficult to integrate stable human evaluations into the development and refinement process of LLMs. \n",
    "\n",
    "\n",
    "In an effort to address this gap, a group of researchers created the “Chatbot Arena,” which is “an open platform for evaluating LLMs based on human preferences” [4]. Much like using a traditional LLM, users can pose questions (hereinafter referred to as “prompts”) and receive answers (hereinafter referred to as “responses”) from an LLM. However, unlike traditional LLMs, users receive two different responses from two different models presented side-by-side. The user is asked to select the response they prefer or select a tie. The model is anonymous, meaning that the user does not know which model produced the responses until after they have selected the winner. This eliminates any potential biases that might arise from name recognition or previous experiences with specific models.\n",
    "\n",
    "\n",
    "Using a select dataset of over 17,000 conversations from the Chatbot Arena, we attempt to investigate and understand user preferences in various LLM interactions. Based on the user’s prompt, the two model responses, the selected “winner,” topic modeling data, and the prompt’s hardness scores, we attempt to complete two primary tasks. The first task (Task A) is the prediction of the winning model between Model A and Model B. The second task (Task B) is the prediction of the hardness score of the user’s prompt. \n",
    "\n",
    "\n",
    "The research questions for this project are as follows:\n",
    "* **RQ1:** *Can we use logistic regression to predict if “Model A” or “Model B” will be selected as the winner by a random user in a Chatbot Arena “battle”?*\n",
    "* **RQ2:** *Can we use linear regression to predict the hardness score of a given prompt?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***In this notebook, you will the find logistic and linear regression models that have been feature engineered to predict model performance in battle and prompt difficulty in response to RQ1 and RQ2. It is the second of two notebooks used for this project.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_nuhZF6AxHc7"
   },
   "source": [
    "# **1. Import libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "igTEjtbQw1AZ",
    "outputId": "ff9147e8-6d63-47c9-a0c3-ca69743f20aa",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "from collections import defaultdict  # https://docs.python.org/3/library/collections.html Return a new dictionary-like object.\n",
    "import json, math, gdown\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import textstat\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "pd.options.display.float_format = '{:.2f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GGtoHeGepX9F",
    "outputId": "c8300420-537e-4295-f6b4-432bbd767a70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings loaded successfully into Colab.\n"
     ]
    }
   ],
   "source": [
    "# Embeddings\n",
    "import requests\n",
    "import numpy as np\n",
    "from io import BytesIO\n",
    "\n",
    "# URL of the raw .npy file\n",
    "file_url = \"https://github.com/dychenster/nlp-chatarena/blob/main/chatbot-arena-prompts-embeddings.npy?raw=true\"\n",
    "\n",
    "# Use requests to get the file content\n",
    "response = requests.get(file_url)\n",
    "\n",
    "# Make sure the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Load the content into a numpy array\n",
    "    content = BytesIO(response.content)\n",
    "    embeddings = np.load(content)\n",
    "    print(\"Embeddings loaded successfully into Colab.\")\n",
    "else:\n",
    "    print(f\"Failed to load the file. Status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 98
    },
    "id": "abIJU_L4w-iF",
    "outputId": "b100d01a-e6cf-4352-cc8e-99548fc04740"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>winner</th>\n",
       "      <th>judge</th>\n",
       "      <th>conversation_a</th>\n",
       "      <th>conversation_b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58210e39b3fd4441a2bd4a518bb44c2d</td>\n",
       "      <td>chatglm-6b</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>model_b</td>\n",
       "      <td>arena_user_973</td>\n",
       "      <td>[{'content': 'What is the difference between O...</td>\n",
       "      <td>[{'content': 'What is the difference between O...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        question_id     model_a    model_b   winner  \\\n",
       "0  58210e39b3fd4441a2bd4a518bb44c2d  chatglm-6b  koala-13b  model_b   \n",
       "\n",
       "            judge                                     conversation_a  \\\n",
       "0  arena_user_973  [{'content': 'What is the difference between O...   \n",
       "\n",
       "                                      conversation_b  \n",
       "0  [{'content': 'What is the difference between O...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load in Chatbot Arena Conversations Dataset\n",
    "\n",
    "# Provide the raw URL of the JSON file\n",
    "url_conversations = \"https://raw.githubusercontent.com/dychenster/nlp-chatarena/main/chatbot-arena-conversations.jsonl.gz\"\n",
    "\n",
    "# Read the JSON file into a DataFrame\n",
    "conversations = pd.read_json(url_conversations, lines=True)\n",
    "\n",
    "# Display the first row of the data\n",
    "conversations.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z7YTglh4A_Pc",
    "outputId": "d7115d98-cdf9-4dfb-b59f-fca3091576d4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25322, 12)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load in Related Topic & Hardness Dataset\n",
    "\n",
    "# Provide the raw URL of the JSON file\n",
    "url_scores = \"https://raw.githubusercontent.com/dychenster/nlp-chatarena/main/chatbot-arena-gpt3-scores.jsonl.gz\"\n",
    "\n",
    "# Read the JSON file into a DataFrame\n",
    "topic_and_hardness = pd.read_json(url_scores, lines=True)\n",
    "\n",
    "# Display the first row of the data\n",
    "topic_and_hardness.head(1)\n",
    "topic_and_hardness.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6_cvv7z9Xg4S"
   },
   "source": [
    "# **2. Data Cleaning & Preparing for Modeling**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a6tXmmjWxWJ1"
   },
   "source": [
    "## 2a. ChatArena Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oxFdY76UxUk3",
    "outputId": "ee22fa89-3b6d-46da-959a-0ba6762fa699"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    What is the difference between OpenCL and CUDA?\n",
       "Name: prompt, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a prompt column\n",
    "conversations[\"prompt\"] = conversations[\"conversation_a\"].str[0].str[\"content\"]\n",
    "conversations[\"prompt\"].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "7lnAy-JUxeGv"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>winner</th>\n",
       "      <th>judge</th>\n",
       "      <th>prompt</th>\n",
       "      <th>model_a_response</th>\n",
       "      <th>model_b_response</th>\n",
       "      <th>prompt_length</th>\n",
       "      <th>response_a_length</th>\n",
       "      <th>response_b_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58210e39b3fd4441a2bd4a518bb44c2d</td>\n",
       "      <td>chatglm-6b</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>model_b</td>\n",
       "      <td>arena_user_973</td>\n",
       "      <td>What is the difference between OpenCL and CUDA?</td>\n",
       "      <td>OpenCL and CUDA are two different programming ...</td>\n",
       "      <td>OpenCL and CUDA are both programming languages...</td>\n",
       "      <td>47</td>\n",
       "      <td>892</td>\n",
       "      <td>1905</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        question_id     model_a    model_b   winner  \\\n",
       "0  58210e39b3fd4441a2bd4a518bb44c2d  chatglm-6b  koala-13b  model_b   \n",
       "\n",
       "            judge                                           prompt  \\\n",
       "0  arena_user_973  What is the difference between OpenCL and CUDA?   \n",
       "\n",
       "                                    model_a_response  \\\n",
       "0  OpenCL and CUDA are two different programming ...   \n",
       "\n",
       "                                    model_b_response  prompt_length  \\\n",
       "0  OpenCL and CUDA are both programming languages...             47   \n",
       "\n",
       "   response_a_length  response_b_length  \n",
       "0                892               1905  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a response columns\n",
    "conversations[\"model_a_response\"] = conversations[\"conversation_a\"].str[1].str[\"content\"]\n",
    "conversations[\"model_b_response\"] = conversations[\"conversation_b\"].str[1].str[\"content\"]\n",
    "\n",
    "# Create prompt and response length columns\n",
    "conversations[\"prompt_length\"] = conversations[\"prompt\"].str.len()\n",
    "conversations[\"response_a_length\"] = conversations[\"model_a_response\"].str.len()\n",
    "conversations[\"response_b_length\"] = conversations[\"model_b_response\"].str.len()\n",
    "\n",
    "# Remove rows with tie (bothbad) and tie as winners\n",
    "conversations = conversations.loc[~conversations[\"winner\"].isin([\"tie (bothbad)\", \"tie\"])]\n",
    "\n",
    "# Remove conversation_a and conversation_b columns\n",
    "conversations.drop(columns=[\"conversation_a\", \"conversation_b\"], inplace=True)\n",
    "conversations.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 205
    },
    "id": "dC3SSL7nzHXk",
    "outputId": "07b51ae8-0ee1-46a8-cbf9-6dcd9a9cd650"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>winner</th>\n",
       "      <th>winner_name</th>\n",
       "      <th>judge</th>\n",
       "      <th>prompt</th>\n",
       "      <th>model_a_response</th>\n",
       "      <th>model_b_response</th>\n",
       "      <th>prompt_length</th>\n",
       "      <th>response_a_length</th>\n",
       "      <th>response_b_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58210e39b3fd4441a2bd4a518bb44c2d</td>\n",
       "      <td>chatglm-6b</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>model_b</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>arena_user_973</td>\n",
       "      <td>What is the difference between OpenCL and CUDA?</td>\n",
       "      <td>OpenCL and CUDA are two different programming ...</td>\n",
       "      <td>OpenCL and CUDA are both programming languages...</td>\n",
       "      <td>47</td>\n",
       "      <td>892</td>\n",
       "      <td>1905</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        question_id     model_a    model_b   winner  \\\n",
       "0  58210e39b3fd4441a2bd4a518bb44c2d  chatglm-6b  koala-13b  model_b   \n",
       "\n",
       "  winner_name           judge  \\\n",
       "0   koala-13b  arena_user_973   \n",
       "\n",
       "                                            prompt  \\\n",
       "0  What is the difference between OpenCL and CUDA?   \n",
       "\n",
       "                                    model_a_response  \\\n",
       "0  OpenCL and CUDA are two different programming ...   \n",
       "\n",
       "                                    model_b_response  prompt_length  \\\n",
       "0  OpenCL and CUDA are both programming languages...             47   \n",
       "\n",
       "   response_a_length  response_b_length  \n",
       "0                892               1905  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reorganize conversations dataframe columns\n",
    "\n",
    "conversations[\"winner_name\"] = np.where(conversations[\"winner\"] == \"model_a\", conversations[\"model_a\"], conversations[\"model_b\"])\n",
    "col = conversations.pop(\"winner_name\")\n",
    "conversations.insert(4, \"winner_name\", col)\n",
    "\n",
    "conversations.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LRZN5CYP6RQs",
    "outputId": "42b74a0e-71ec-4146-9bf0-b27038c51de1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gpt-4                     0.85\n",
       "claude-v1                 0.80\n",
       "claude-instant-v1         0.76\n",
       "gpt-3.5-turbo             0.71\n",
       "vicuna-13b                0.62\n",
       "guanaco-33b               0.60\n",
       "palm-2                    0.59\n",
       "wizardlm-13b              0.54\n",
       "koala-13b                 0.51\n",
       "vicuna-7b                 0.45\n",
       "mpt-7b-chat               0.35\n",
       "alpaca-13b                0.35\n",
       "oasst-pythia-12b          0.35\n",
       "gpt4all-13b-snoozy        0.34\n",
       "RWKV-4-Raven-14B          0.34\n",
       "chatglm-6b                0.30\n",
       "fastchat-t5-3b            0.30\n",
       "stablelm-tuned-alpha-7b   0.26\n",
       "dolly-v2-12b              0.23\n",
       "llama-13b                 0.20\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate win rate of each model\n",
    "\n",
    "conversations[\"winner_name\"].value_counts()\n",
    "\n",
    "win_rates = conversations[\"winner_name\"].value_counts() / (conversations[\"model_a\"].value_counts() + conversations[\"model_b\"].value_counts())\n",
    "win_rates.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "dBhNz9hYxyn0",
    "outputId": "6ab9daea-5f88-42e4-93a1-2f9b9faf87fd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The proportion of times the longer response was chosen as the 'winner': 0.6331321260898726\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Look at how often the longer responses were selected as the \"winner\"\n",
    "\n",
    "conversations[\"length_difference\"] = conversations[\"response_a_length\"] - conversations[\"response_b_length\"]\n",
    "conversations[\"longer_response\"] = conversations.apply(lambda row: \"model_a\" if row[\"length_difference\"] > 0 else \"model_b\", axis=1)\n",
    "\n",
    "longer_response_chosen_count = (conversations['winner'] == conversations['longer_response']).sum()\n",
    "\n",
    "display(\"The proportion of times the longer response was chosen as the 'winner': \" + str(longer_response_chosen_count/len(conversations)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kA0iYrHg5KFn"
   },
   "source": [
    "## 2b. Topic & Hardness Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vjydUgbO5TPC",
    "outputId": "a615798d-abcd-462b-cdf5-55844a08530d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score_value_1    0\n",
      "score_value_2    0\n",
      "score_value_3    0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "question_id                         object\n",
       "prompt                              object\n",
       "openai_scores_raw_choices_nested    object\n",
       "topic_modeling_1                    object\n",
       "score_reason_1                      object\n",
       "score_value_1                        int64\n",
       "topic_modeling_2                    object\n",
       "score_reason_2                      object\n",
       "score_value_2                        int64\n",
       "topic_modeling_3                    object\n",
       "score_reason_3                      object\n",
       "score_value_3                        int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove null values from scores values\n",
    "topic_and_hardness = topic_and_hardness.dropna(subset=['score_value_1', 'score_value_2', 'score_value_3'])\n",
    "print(topic_and_hardness[['score_value_1', 'score_value_2', 'score_value_3']].isna().sum())\n",
    "\n",
    "# Change all score values to be numeric\n",
    "topic_and_hardness.loc[:,'score_value_1'] = pd.to_numeric(topic_and_hardness['score_value_1'], errors='coerce')\n",
    "topic_and_hardness.loc[:,'score_value_2'] = pd.to_numeric(topic_and_hardness['score_value_2'], errors='coerce')\n",
    "topic_and_hardness.loc[:,'score_value_3'] = pd.to_numeric(topic_and_hardness['score_value_3'], errors='coerce')\n",
    "\n",
    "# Drop any resulting null values\n",
    "topic_and_hardness= topic_and_hardness.dropna(subset=['score_value_1', 'score_value_2', 'score_value_3'])\n",
    "\n",
    "# Change all score values to be integers\n",
    "topic_and_hardness['score_value_1'] = topic_and_hardness['score_value_1'].astype(np.int64)\n",
    "topic_and_hardness['score_value_2'] = topic_and_hardness['score_value_2'].astype(np.int64)\n",
    "topic_and_hardness['score_value_3'] = topic_and_hardness['score_value_3'].astype(np.int64)\n",
    "\n",
    "# Verify all score values are integers\n",
    "topic_and_hardness.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3m38Qydp6o9w"
   },
   "source": [
    "## 2c. Merged Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 234
    },
    "id": "EDfFPtGf5hV7",
    "outputId": "7570e129-a3e3-41a1-acd0-583be5e66603"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>winner</th>\n",
       "      <th>winner_name</th>\n",
       "      <th>judge</th>\n",
       "      <th>prompt_x</th>\n",
       "      <th>model_a_response</th>\n",
       "      <th>model_b_response</th>\n",
       "      <th>prompt_length</th>\n",
       "      <th>...</th>\n",
       "      <th>openai_scores_raw_choices_nested</th>\n",
       "      <th>topic_modeling_1</th>\n",
       "      <th>score_reason_1</th>\n",
       "      <th>score_value_1</th>\n",
       "      <th>topic_modeling_2</th>\n",
       "      <th>score_reason_2</th>\n",
       "      <th>score_value_2</th>\n",
       "      <th>topic_modeling_3</th>\n",
       "      <th>score_reason_3</th>\n",
       "      <th>score_value_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58210e39b3fd4441a2bd4a518bb44c2d</td>\n",
       "      <td>chatglm-6b</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>model_b</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>arena_user_973</td>\n",
       "      <td>What is the difference between OpenCL and CUDA?</td>\n",
       "      <td>OpenCL and CUDA are two different programming ...</td>\n",
       "      <td>OpenCL and CUDA are both programming languages...</td>\n",
       "      <td>47</td>\n",
       "      <td>...</td>\n",
       "      <td>[{'finish_reason': 'stop', 'index': 0, 'logpro...</td>\n",
       "      <td>Technical Comparison</td>\n",
       "      <td>This prompt requires the AI to accurately comp...</td>\n",
       "      <td>9</td>\n",
       "      <td>Software Comparison</td>\n",
       "      <td>This prompt assesses the AI's factual accuracy...</td>\n",
       "      <td>8</td>\n",
       "      <td>Comparison, Technology</td>\n",
       "      <td>This prompt requires the AI to demonstrate kno...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        question_id     model_a    model_b   winner  \\\n",
       "0  58210e39b3fd4441a2bd4a518bb44c2d  chatglm-6b  koala-13b  model_b   \n",
       "\n",
       "  winner_name           judge  \\\n",
       "0   koala-13b  arena_user_973   \n",
       "\n",
       "                                          prompt_x  \\\n",
       "0  What is the difference between OpenCL and CUDA?   \n",
       "\n",
       "                                    model_a_response  \\\n",
       "0  OpenCL and CUDA are two different programming ...   \n",
       "\n",
       "                                    model_b_response  prompt_length  ...  \\\n",
       "0  OpenCL and CUDA are both programming languages...             47  ...   \n",
       "\n",
       "                    openai_scores_raw_choices_nested      topic_modeling_1  \\\n",
       "0  [{'finish_reason': 'stop', 'index': 0, 'logpro...  Technical Comparison   \n",
       "\n",
       "                                      score_reason_1 score_value_1  \\\n",
       "0  This prompt requires the AI to accurately comp...             9   \n",
       "\n",
       "      topic_modeling_2                                     score_reason_2  \\\n",
       "0  Software Comparison  This prompt assesses the AI's factual accuracy...   \n",
       "\n",
       "  score_value_2        topic_modeling_3  \\\n",
       "0             8  Comparison, Technology   \n",
       "\n",
       "                                      score_reason_3 score_value_3  \n",
       "0  This prompt requires the AI to demonstrate kno...             9  \n",
       "\n",
       "[1 rows x 25 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge conversations and topic/hardness dataframes\n",
    "merged_df = conversations.merge(topic_and_hardness, on=\"question_id\")\n",
    "merged_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 205
    },
    "id": "iOuQmbvTA5mh",
    "outputId": "a8cbcb86-7f4d-43cd-c0a6-a4d05f66f007"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>winner</th>\n",
       "      <th>winner_name</th>\n",
       "      <th>judge</th>\n",
       "      <th>prompt_x</th>\n",
       "      <th>model_a_response</th>\n",
       "      <th>model_b_response</th>\n",
       "      <th>prompt_length</th>\n",
       "      <th>response_a_length</th>\n",
       "      <th>response_b_length</th>\n",
       "      <th>length_difference</th>\n",
       "      <th>longer_response</th>\n",
       "      <th>score_value_1</th>\n",
       "      <th>score_value_2</th>\n",
       "      <th>score_value_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58210e39b3fd4441a2bd4a518bb44c2d</td>\n",
       "      <td>chatglm-6b</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>model_b</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>arena_user_973</td>\n",
       "      <td>What is the difference between OpenCL and CUDA?</td>\n",
       "      <td>OpenCL and CUDA are two different programming ...</td>\n",
       "      <td>OpenCL and CUDA are both programming languages...</td>\n",
       "      <td>47</td>\n",
       "      <td>892</td>\n",
       "      <td>1905</td>\n",
       "      <td>-1013</td>\n",
       "      <td>model_b</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        question_id     model_a    model_b   winner  \\\n",
       "0  58210e39b3fd4441a2bd4a518bb44c2d  chatglm-6b  koala-13b  model_b   \n",
       "\n",
       "  winner_name           judge  \\\n",
       "0   koala-13b  arena_user_973   \n",
       "\n",
       "                                          prompt_x  \\\n",
       "0  What is the difference between OpenCL and CUDA?   \n",
       "\n",
       "                                    model_a_response  \\\n",
       "0  OpenCL and CUDA are two different programming ...   \n",
       "\n",
       "                                    model_b_response  prompt_length  \\\n",
       "0  OpenCL and CUDA are both programming languages...             47   \n",
       "\n",
       "   response_a_length  response_b_length  length_difference longer_response  \\\n",
       "0                892               1905              -1013         model_b   \n",
       "\n",
       "   score_value_1  score_value_2  score_value_3  \n",
       "0              9              8              9  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove certain columns\n",
    "merged_df.drop(columns=[\"openai_scores_raw_choices_nested\", \"topic_modeling_1\", \"topic_modeling_2\", \"topic_modeling_3\", \"score_reason_1\", \"score_reason_2\", \"score_reason_3\", \"prompt_y\"], inplace=True)\n",
    "merged_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 205
    },
    "id": "JVxNF2_wBrN3",
    "outputId": "dd730590-704d-4cfa-eb9b-814159f2011e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>winner</th>\n",
       "      <th>winner_name</th>\n",
       "      <th>judge</th>\n",
       "      <th>prompt</th>\n",
       "      <th>model_a_response</th>\n",
       "      <th>model_b_response</th>\n",
       "      <th>prompt_length</th>\n",
       "      <th>response_a_length</th>\n",
       "      <th>response_b_length</th>\n",
       "      <th>length_difference</th>\n",
       "      <th>longer_response</th>\n",
       "      <th>score_value_1</th>\n",
       "      <th>score_value_2</th>\n",
       "      <th>score_value_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58210e39b3fd4441a2bd4a518bb44c2d</td>\n",
       "      <td>chatglm-6b</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>model_b</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>arena_user_973</td>\n",
       "      <td>What is the difference between OpenCL and CUDA?</td>\n",
       "      <td>OpenCL and CUDA are two different programming ...</td>\n",
       "      <td>OpenCL and CUDA are both programming languages...</td>\n",
       "      <td>47</td>\n",
       "      <td>892</td>\n",
       "      <td>1905</td>\n",
       "      <td>-1013</td>\n",
       "      <td>model_b</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        question_id     model_a    model_b   winner  \\\n",
       "0  58210e39b3fd4441a2bd4a518bb44c2d  chatglm-6b  koala-13b  model_b   \n",
       "\n",
       "  winner_name           judge  \\\n",
       "0   koala-13b  arena_user_973   \n",
       "\n",
       "                                            prompt  \\\n",
       "0  What is the difference between OpenCL and CUDA?   \n",
       "\n",
       "                                    model_a_response  \\\n",
       "0  OpenCL and CUDA are two different programming ...   \n",
       "\n",
       "                                    model_b_response  prompt_length  \\\n",
       "0  OpenCL and CUDA are both programming languages...             47   \n",
       "\n",
       "   response_a_length  response_b_length  length_difference longer_response  \\\n",
       "0                892               1905              -1013         model_b   \n",
       "\n",
       "   score_value_1  score_value_2  score_value_3  \n",
       "0              9              8              9  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename columns\n",
    "merged_df.rename(columns={\"prompt_x\":\"prompt\"}, inplace=True)\n",
    "merged_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "71tOquRW7Dpv",
    "outputId": "82ef28bb-bc8c-4497-d6e2-468c971960dd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "winner_name\n",
       "claude-instant-v1         7.26\n",
       "gpt-4                     7.25\n",
       "gpt-3.5-turbo             7.22\n",
       "vicuna-7b                 7.21\n",
       "claude-v1                 7.20\n",
       "palm-2                    7.14\n",
       "fastchat-t5-3b            7.12\n",
       "wizardlm-13b              7.10\n",
       "oasst-pythia-12b          7.07\n",
       "vicuna-13b                7.07\n",
       "koala-13b                 7.06\n",
       "RWKV-4-Raven-14B          7.05\n",
       "stablelm-tuned-alpha-7b   7.05\n",
       "mpt-7b-chat               7.00\n",
       "guanaco-33b               6.97\n",
       "gpt4all-13b-snoozy        6.93\n",
       "dolly-v2-12b              6.91\n",
       "alpaca-13b                6.84\n",
       "chatglm-6b                6.81\n",
       "llama-13b                 6.67\n",
       "Name: average_score, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add total (average) score for each battle\n",
    "merged_df[\"average_score\"] = (merged_df[\"score_value_1\"] + merged_df[\"score_value_2\"] + merged_df[\"score_value_3\"])/ 3\n",
    "\n",
    "# Average hardness score per model (in winning rows)\n",
    "average_hardness_per_model = merged_df.groupby(\"winner_name\")[\"average_score\"].mean().sort_values(ascending=False)\n",
    "average_hardness_per_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 205
    },
    "id": "MauQo_bu8GUv",
    "outputId": "f1542a59-b89e-4e6b-cf89-8c1b23e784bc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>winner</th>\n",
       "      <th>winner_name</th>\n",
       "      <th>judge</th>\n",
       "      <th>prompt</th>\n",
       "      <th>model_a_response</th>\n",
       "      <th>model_b_response</th>\n",
       "      <th>prompt_length</th>\n",
       "      <th>response_a_length</th>\n",
       "      <th>response_b_length</th>\n",
       "      <th>length_difference</th>\n",
       "      <th>longer_response</th>\n",
       "      <th>score_value_1</th>\n",
       "      <th>score_value_2</th>\n",
       "      <th>score_value_3</th>\n",
       "      <th>average_score</th>\n",
       "      <th>total_hardness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58210e39b3fd4441a2bd4a518bb44c2d</td>\n",
       "      <td>chatglm-6b</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>model_b</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>arena_user_973</td>\n",
       "      <td>What is the difference between OpenCL and CUDA?</td>\n",
       "      <td>OpenCL and CUDA are two different programming ...</td>\n",
       "      <td>OpenCL and CUDA are both programming languages...</td>\n",
       "      <td>47</td>\n",
       "      <td>892</td>\n",
       "      <td>1905</td>\n",
       "      <td>-1013</td>\n",
       "      <td>model_b</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>8.67</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        question_id     model_a    model_b   winner  \\\n",
       "0  58210e39b3fd4441a2bd4a518bb44c2d  chatglm-6b  koala-13b  model_b   \n",
       "\n",
       "  winner_name           judge  \\\n",
       "0   koala-13b  arena_user_973   \n",
       "\n",
       "                                            prompt  \\\n",
       "0  What is the difference between OpenCL and CUDA?   \n",
       "\n",
       "                                    model_a_response  \\\n",
       "0  OpenCL and CUDA are two different programming ...   \n",
       "\n",
       "                                    model_b_response  prompt_length  \\\n",
       "0  OpenCL and CUDA are both programming languages...             47   \n",
       "\n",
       "   response_a_length  response_b_length  length_difference longer_response  \\\n",
       "0                892               1905              -1013         model_b   \n",
       "\n",
       "   score_value_1  score_value_2  score_value_3  average_score  total_hardness  \n",
       "0              9              8              9           8.67              26  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute total hardness of each prompt\n",
    "merged_df[\"total_hardness\"] = merged_df[\"score_value_1\"] + merged_df[\"score_value_2\"] + merged_df[\"score_value_3\"]\n",
    "merged_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "Uxx4-x8EaM8g"
   },
   "outputs": [],
   "source": [
    "# Use texstat library - Flesch Reading Ease\n",
    "merged_df[\"model_a_complexity\"] = (merged_df[\"model_a_response\"]).apply(textstat.flesch_reading_ease)\n",
    "merged_df[\"model_b_complexity\"] = (merged_df[\"model_b_response\"]).apply(textstat.flesch_reading_ease)\n",
    "merged_df[\"prompt_complexity\"] = (merged_df[\"prompt\"]).apply(textstat.flesch_reading_ease)\n",
    "\n",
    "#90-100\tVery Easy\n",
    "#80-89\tEasy\n",
    "#70-79\tFairly Easy\n",
    "#60-69\tStandard\n",
    "#50-59\tFairly Difficult\n",
    "#30-49\tDifficult\n",
    "#0-29\tVery Confusing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "1kJdTxREaP_k"
   },
   "outputs": [],
   "source": [
    "# Readability consensus (grade level)\n",
    "merged_df[\"model_a_grade\"] = merged_df[\"model_a_response\"].apply(lambda x: textstat.text_standard(x, float_output=True))\n",
    "merged_df[\"model_b_grade\"] = merged_df[\"model_b_response\"].apply(lambda x: textstat.text_standard(x, float_output=True))\n",
    "merged_df[\"prompt_grade\"] = merged_df[\"prompt\"].apply(lambda x: textstat.text_standard(x, float_output=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "7qoNk9vsaXEj"
   },
   "outputs": [],
   "source": [
    "# Reading time\n",
    "merged_df[\"model_a_time\"] = merged_df[\"model_a_response\"].apply(lambda x: textstat.reading_time(x, ms_per_char=14.69))\n",
    "merged_df[\"model_b_time\"] = merged_df[\"model_b_response\"].apply(lambda x: textstat.reading_time(x, ms_per_char=14.69))\n",
    "merged_df[\"prompt_time\"] = merged_df[\"prompt\"].apply(lambda x: textstat.reading_time(x, ms_per_char=14.69))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vxjJZgHvayDO",
    "outputId": "54362dff-1957-4b88-cd94-526369d9e2ff"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17045, 28)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W36rhUzpzu63"
   },
   "source": [
    "# **3. Task A** \n",
    "# Given a prompt, can we predict which model’s response will win the user vote?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "NKJerl23zxJs"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "URHHcAFFczsY"
   },
   "source": [
    "## 3a. Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "k6_6Xo0yG0LA"
   },
   "outputs": [],
   "source": [
    "# One-hot encode the model names\n",
    "\n",
    "# Create an array with all the model names\n",
    "models_combined = pd.concat([merged_df[\"model_a\"], merged_df[\"model_b\"]]).unique()\n",
    "\n",
    "# Initialize the columns to zero\n",
    "for model in models_combined:\n",
    "    merged_df[model] = 0\n",
    "\n",
    "# Use logical OR to combine the one-hot encoding for both model_a and model_b\n",
    "for model in models_combined:\n",
    "    merged_df[model] = ((merged_df[\"model_a\"] == model) | (merged_df[\"model_b\"] == model)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "M03ykkLMEDmo"
   },
   "outputs": [],
   "source": [
    "# Add a new feature for the win rate of model_a\n",
    "merged_df['model_a_win_rate'] = merged_df['model_a'].map(win_rates)\n",
    "\n",
    "# Add a new feature for the win rate of model_b\n",
    "merged_df['model_b_win_rate'] = merged_df['model_b'].map(win_rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q3vAH9zt36MN",
    "outputId": "f2f45ffe-f1de-49df-f42a-ff3dce61bc9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.750073335288941\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     model_a       0.73      0.77      0.75      1665\n",
      "     model_b       0.77      0.73      0.75      1744\n",
      "\n",
      "    accuracy                           0.75      3409\n",
      "   macro avg       0.75      0.75      0.75      3409\n",
      "weighted avg       0.75      0.75      0.75      3409\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# merged_df[\"winner_binary\"] = (merged_df['winner'] == 'model_b')\n",
    "\n",
    "# Features for model\n",
    "features = [\"prompt_length\", \"prompt_complexity\", \"prompt_grade\", \"prompt_time\", \"model_a_win_rate\", \"model_b_win_rate\",\n",
    "            'chatglm-6b', 'koala-13b', 'vicuna-13b', 'stablelm-tuned-alpha-7b','oasst-pythia-12b', 'dolly-v2-12b', 'alpaca-13b', 'llama-13b', 'fastchat-t5-3b', 'gpt-3.5-turbo', \\\n",
    "            'gpt-4', 'claude-v1', 'RWKV-4-Raven-14B', 'mpt-7b-chat', 'palm-2', 'claude-instant-v1', 'vicuna-7b', 'wizardlm-13b', 'gpt4all-13b-snoozy', 'guanaco-33b']\n",
    "\n",
    "\n",
    "X = merged_df[features]\n",
    "y = merged_df[\"winner\"]\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.20, random_state=42)\n",
    "\n",
    "# Create a logistic regression model\n",
    "model_task_a = LogisticRegression(max_iter=2000)\n",
    "\n",
    "# Train the model\n",
    "model_task_a.fit(X_train, y_train)\n",
    "\n",
    "# Predict the test set\n",
    "y_pred_encoded = model_task_a.predict(X_test)\n",
    "\n",
    "# Decode the predictions back to 'model_a' and 'model_b'\n",
    "y_pred = le.inverse_transform(y_pred_encoded)\n",
    "\n",
    "# Calculate the accuracy, precision, recall\n",
    "accuracy = accuracy_score(y_test, y_pred_encoded)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(classification_report(y_test, y_pred_encoded, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 650
    },
    "id": "ztHlziN3CUlj",
    "outputId": "930e0b9b-e34d-4268-e594-5e5ec7c478e1"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generating the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_encoded)\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=['Predicted Model A', 'Predicted Model B'],\n",
    "            yticklabels=['Actual Model A', 'Actual Model B'])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H-H8pjmJ2B0N",
    "outputId": "20e1b52b-3f2e-443e-fe5d-923ae5775aec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracies for each fold: [0.75007334 0.75359343 0.74655324 0.73364623 0.74185978]\n",
      "Mean CV Accuracy: 0.7451452038721034\n"
     ]
    }
   ],
   "source": [
    "# K-Fold Cross-Validation\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "X = merged_df[features]\n",
    "y = merged_df[\"winner\"]\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "cv_scores = cross_val_score(model_task_a, X, y, cv=kf, scoring=\"accuracy\")\n",
    "\n",
    "# Print the accuracy for each fold\n",
    "print(f'Accuracies for each fold: {cv_scores}')\n",
    "\n",
    "# Print the mean of the cross-validation accuracy\n",
    "print(f'Mean CV Accuracy: {cv_scores.mean()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RG2V5DLj3w4s"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jBn1QX1WCyxq"
   },
   "source": [
    "# **4. Task B**\n",
    "# Can we guess the hardness score of a given prompt?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0YGVqLsxqRSs",
    "outputId": "9b5a839b-a057-4b22-c4c6-3d95a0642b71"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/mayaschoucair/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# IMPORTS\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Text Libraries\n",
    "from textstat import flesch_kincaid_grade, gunning_fog\n",
    "import textstat\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hXv7w6lAXzC7",
    "outputId": "7514ae6e-088b-465c-f5c9-3078925ca76c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "qH2-3gqVYlJ7",
    "outputId": "2b75e2d5-b82c-4900-8870-d96829e826ae"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>e_0</th>\n",
       "      <th>e_1</th>\n",
       "      <th>e_2</th>\n",
       "      <th>e_3</th>\n",
       "      <th>e_4</th>\n",
       "      <th>e_5</th>\n",
       "      <th>e_6</th>\n",
       "      <th>e_7</th>\n",
       "      <th>e_8</th>\n",
       "      <th>e_9</th>\n",
       "      <th>...</th>\n",
       "      <th>e_246</th>\n",
       "      <th>e_247</th>\n",
       "      <th>e_248</th>\n",
       "      <th>e_249</th>\n",
       "      <th>e_250</th>\n",
       "      <th>e_251</th>\n",
       "      <th>e_252</th>\n",
       "      <th>e_253</th>\n",
       "      <th>e_254</th>\n",
       "      <th>e_255</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.12</td>\n",
       "      <td>-0.12</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.09</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>0.09</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.06</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>-0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>0.04</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>0.04</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.09</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.04</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.04</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.02</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>0.06</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.06</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.05</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>0.05</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.07</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25317</th>\n",
       "      <td>-0.03</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.08</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>0.06</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>-0.12</td>\n",
       "      <td>0.06</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25318</th>\n",
       "      <td>0.05</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.08</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>...</td>\n",
       "      <td>0.04</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.04</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>-0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25319</th>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>0.07</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>0.08</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25320</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.08</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.07</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25321</th>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.02</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.14</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.08</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25322 rows × 256 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        e_0   e_1   e_2   e_3   e_4   e_5   e_6   e_7   e_8   e_9  ...  e_246  \\\n",
       "0     -0.12 -0.12  0.04  0.02  0.09 -0.03  0.00 -0.08  0.09 -0.00  ...  -0.02   \n",
       "1      0.01  0.03 -0.09  0.04 -0.08 -0.05 -0.05 -0.03 -0.08  0.04  ...  -0.01   \n",
       "2     -0.04 -0.11 -0.02 -0.04  0.04 -0.05 -0.01  0.03  0.03  0.02  ...  -0.08   \n",
       "3     -0.05 -0.00  0.09  0.03 -0.04 -0.10 -0.02  0.01 -0.06  0.05  ...  -0.07   \n",
       "4     -0.04  0.05  0.06  0.05  0.05 -0.02  0.06  0.05 -0.07 -0.02  ...   0.01   \n",
       "...     ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...    ...   \n",
       "25317 -0.03 -0.03 -0.02 -0.09 -0.09 -0.02  0.08 -0.01  0.05 -0.03  ...  -0.10   \n",
       "25318  0.05 -0.14  0.05  0.13  0.09  0.01  0.10  0.08 -0.04 -0.04  ...   0.04   \n",
       "25319  0.02 -0.03  0.07 -0.09 -0.03 -0.03  0.00 -0.08 -0.02 -0.04  ...  -0.01   \n",
       "25320  0.02  0.04  0.08 -0.11 -0.03 -0.03  0.03  0.02  0.04  0.07  ...  -0.02   \n",
       "25321 -0.04  0.01 -0.00 -0.03 -0.06 -0.13 -0.01  0.03  0.05  0.02  ...   0.03   \n",
       "\n",
       "       e_247  e_248  e_249  e_250  e_251  e_252  e_253  e_254  e_255  \n",
       "0      -0.11   0.03   0.01   0.02   0.06  -0.16  -0.02  -0.04  -0.04  \n",
       "1      -0.03  -0.01   0.03  -0.02  -0.08   0.06   0.09  -0.05   0.00  \n",
       "2       0.06  -0.06   0.06   0.03   0.06  -0.04  -0.14   0.00   0.00  \n",
       "3      -0.10   0.15   0.03  -0.01   0.06   0.03  -0.03   0.05  -0.06  \n",
       "4      -0.04  -0.01   0.07   0.07  -0.04  -0.08  -0.05   0.01  -0.01  \n",
       "...      ...    ...    ...    ...    ...    ...    ...    ...    ...  \n",
       "25317  -0.07   0.06  -0.01  -0.06  -0.12   0.06  -0.05  -0.07   0.04  \n",
       "25318  -0.00   0.06   0.04  -0.01  -0.08  -0.07   0.03  -0.10  -0.03  \n",
       "25319  -0.08   0.08  -0.05  -0.05   0.03  -0.01  -0.06  -0.02   0.06  \n",
       "25320  -0.05   0.05  -0.02  -0.02  -0.00   0.05  -0.02  -0.05   0.03  \n",
       "25321  -0.08  -0.01   0.02   0.14  -0.00   0.01   0.08  -0.02  -0.11  \n",
       "\n",
       "[25322 rows x 256 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_df = pd.DataFrame(embeddings, columns=[f'e_{i}' for i in range(256)])\n",
    "embeddings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NamvLlhSXGh0",
    "outputId": "4e8f887e-a3d7-49b8-d693-193389d220a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score_value_1    0\n",
      "score_value_2    0\n",
      "score_value_3    0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "question_id       object\n",
       "prompt            object\n",
       "score_value_1      int64\n",
       "score_value_2      int64\n",
       "score_value_3      int64\n",
       "                  ...   \n",
       "e_251            float32\n",
       "e_252            float32\n",
       "e_253            float32\n",
       "e_254            float32\n",
       "e_255            float32\n",
       "Length: 261, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up task B df\n",
    "\n",
    "task_b_df = pd.read_json(url_scores, lines=True)[['question_id', 'prompt', 'score_value_1', 'score_value_2', 'score_value_3']]\n",
    "# task_b_df = task_b_df.dropna(subset=['score_value_1', 'score_value_2', 'score_value_3'])\n",
    "# task_b_df['score_value_1'].astype(int)\n",
    "# task_b_df['average_score'] = task_b_df[['score_value_1', 'score_value_2','score_value_3']].mean(axis=1)\n",
    "\n",
    "# Add embeddings\n",
    "task_b_df.reset_index(drop=True, inplace=True)\n",
    "embeddings_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "task_b_df = pd.concat([task_b_df, embeddings_df], axis=1)\n",
    "\n",
    "# Remove null values from scores values\n",
    "# topic_and_hardness = topic_and_hardness.dropna(subset=['score_value_1', 'score_value_2', 'score_value_3'])\n",
    "# print(topic_and_hardness[['score_value_1', 'score_value_2', 'score_value_3']].isna().sum())\n",
    "task_b_df = task_b_df.dropna(subset=['score_value_1', 'score_value_2', 'score_value_3'])\n",
    "print(task_b_df[['score_value_1', 'score_value_2', 'score_value_3']].isna().sum())\n",
    "\n",
    "# Change all score values to be numeric\n",
    "task_b_df.loc[:,'score_value_1'] = pd.to_numeric(task_b_df['score_value_1'], errors='coerce')\n",
    "task_b_df.loc[:,'score_value_2'] = pd.to_numeric(task_b_df['score_value_2'], errors='coerce')\n",
    "task_b_df.loc[:,'score_value_3'] = pd.to_numeric(task_b_df['score_value_3'], errors='coerce')\n",
    "\n",
    "# Drop any resulting null values\n",
    "task_b_df = task_b_df.dropna(subset=['score_value_1', 'score_value_2', 'score_value_3'])\n",
    "\n",
    "# Change all score values to be integers\n",
    "task_b_df['score_value_1'] = task_b_df['score_value_1'].astype(np.int64)\n",
    "task_b_df['score_value_2'] = task_b_df['score_value_2'].astype(np.int64)\n",
    "task_b_df['score_value_3'] = task_b_df['score_value_3'].astype(np.int64)\n",
    "\n",
    "# Verify all score values are integers\n",
    "task_b_df.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-rmOvRrAz-i4",
    "outputId": "3e4e9636-5367-4399-c31d-9aa179a07162"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24106, 261)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_b_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 234
    },
    "id": "WNw9MCZJ3clx",
    "outputId": "5dc04595-1a8f-47b7-aaa2-764636571793"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>prompt</th>\n",
       "      <th>score_value_1</th>\n",
       "      <th>score_value_2</th>\n",
       "      <th>score_value_3</th>\n",
       "      <th>e_0</th>\n",
       "      <th>e_1</th>\n",
       "      <th>e_2</th>\n",
       "      <th>e_3</th>\n",
       "      <th>e_4</th>\n",
       "      <th>...</th>\n",
       "      <th>e_247</th>\n",
       "      <th>e_248</th>\n",
       "      <th>e_249</th>\n",
       "      <th>e_250</th>\n",
       "      <th>e_251</th>\n",
       "      <th>e_252</th>\n",
       "      <th>e_253</th>\n",
       "      <th>e_254</th>\n",
       "      <th>e_255</th>\n",
       "      <th>average_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58210e39b3fd4441a2bd4a518bb44c2d</td>\n",
       "      <td>What is the difference between OpenCL and CUDA?</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>-0.12</td>\n",
       "      <td>-0.12</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.09</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.06</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>8.67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 262 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        question_id  \\\n",
       "0  58210e39b3fd4441a2bd4a518bb44c2d   \n",
       "\n",
       "                                            prompt  score_value_1  \\\n",
       "0  What is the difference between OpenCL and CUDA?              9   \n",
       "\n",
       "   score_value_2  score_value_3   e_0   e_1  e_2  e_3  e_4  ...  e_247  e_248  \\\n",
       "0              8              9 -0.12 -0.12 0.04 0.02 0.09  ...  -0.11   0.03   \n",
       "\n",
       "   e_249  e_250  e_251  e_252  e_253  e_254  e_255  average_score  \n",
       "0   0.01   0.02   0.06  -0.16  -0.02  -0.04  -0.04           8.67  \n",
       "\n",
       "[1 rows x 262 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate and add average score of each prompt to dataframe\n",
    "task_b_df['average_score'] = task_b_df[['score_value_1', 'score_value_2', 'score_value_3']].mean(axis=1)\n",
    "task_b_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 457
    },
    "id": "X3qFU8-s6e75",
    "outputId": "e0453584-bf8e-4b1c-cc14-6405af7f7611"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Frequency of Hardness Scores\n",
    "\n",
    "plt.hist(task_b_df['average_score'])\n",
    "plt.title('Frequency of Hardness Score (Auto-Binned)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 457
    },
    "id": "PhsNM8wS6x-7",
    "outputId": "4bf14b99-a69e-4d87-a2bf-deeb53cdd958"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Frequency of Hardness Scores Rounded Before Binning\n",
    "\n",
    "plt.hist(task_b_df['average_score'].round().astype(int))\n",
    "plt.title('Frequency of Hardness Score (Rounded Before Binning)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 234
    },
    "id": "J-bhW2GphjbG",
    "outputId": "70723ba0-3558-4975-d38a-8b694a5c5534"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>prompt</th>\n",
       "      <th>score_value_1</th>\n",
       "      <th>score_value_2</th>\n",
       "      <th>score_value_3</th>\n",
       "      <th>e_0</th>\n",
       "      <th>e_1</th>\n",
       "      <th>e_2</th>\n",
       "      <th>e_3</th>\n",
       "      <th>e_4</th>\n",
       "      <th>...</th>\n",
       "      <th>e_247</th>\n",
       "      <th>e_248</th>\n",
       "      <th>e_249</th>\n",
       "      <th>e_250</th>\n",
       "      <th>e_251</th>\n",
       "      <th>e_252</th>\n",
       "      <th>e_253</th>\n",
       "      <th>e_254</th>\n",
       "      <th>e_255</th>\n",
       "      <th>average_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58210e39b3fd4441a2bd4a518bb44c2d</td>\n",
       "      <td>What is the difference between OpenCL and CUDA?</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>-0.12</td>\n",
       "      <td>-0.12</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.09</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.06</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>8.67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 262 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        question_id  \\\n",
       "0  58210e39b3fd4441a2bd4a518bb44c2d   \n",
       "\n",
       "                                            prompt  score_value_1  \\\n",
       "0  What is the difference between OpenCL and CUDA?              9   \n",
       "\n",
       "   score_value_2  score_value_3   e_0   e_1  e_2  e_3  e_4  ...  e_247  e_248  \\\n",
       "0              8              9 -0.12 -0.12 0.04 0.02 0.09  ...  -0.11   0.03   \n",
       "\n",
       "   e_249  e_250  e_251  e_252  e_253  e_254  e_255  average_score  \n",
       "0   0.01   0.02   0.06  -0.16  -0.02  -0.04  -0.04           8.67  \n",
       "\n",
       "[1 rows x 262 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_b_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6wiug86AegOD"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ICyUjk6EeguM"
   },
   "source": [
    "# 4a. Linear Regression Models (Feature Set 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Features include embeddings only*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c1dCDNa2Zapp"
   },
   "source": [
    "**MODEL 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FfrYyedAegSn",
    "outputId": "9a68c58b-5c3d-457b-82c7-5c42bace149f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24106, 256)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature Set 1: Just embeddings\n",
    "\n",
    "# embeddings_matrix = task_b_df.drop(columns = ['question_id', 'cluster', 'score_value_1', 'score_value_2', 'score_value_3', 'average_score', 'total_hardness', 'prompt', 'cluster_score'])\n",
    "embeddings_matrix = task_b_df.drop(columns = ['question_id', 'score_value_1', 'score_value_2', 'score_value_3', 'average_score', 'prompt'])\n",
    "embeddings_matrix = embeddings_matrix.reset_index(drop=True)\n",
    "embeddings_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K0lECWAibded",
    "outputId": "47a40f6f-9260-4011-84ae-a65eb3e057c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 2.0951887183741187\n"
     ]
    }
   ],
   "source": [
    "# Feature Set 1 (Just embeddings)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(embeddings_matrix, task_b_df['average_score'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Model training\n",
    "model1a = LinearRegression()\n",
    "model1a.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "predictions1a = model1a.predict(X_test).round().astype(int)\n",
    "mse1a = mean_squared_error(y_test, predictions1a)\n",
    "print(\"Mean Squared Error:\", mse1a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "va_XsK9Q7wFx",
    "outputId": "4437f6ce-16da-402a-90cc-20650100fda6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE scores for each fold: [2.00565271 1.98727935 1.96684599 1.90532331 2.01105699]\n",
      "Average MSE: 1.9752316690203844\n"
     ]
    }
   ],
   "source": [
    "# 5 K-Fold Cross-Validation\n",
    "\n",
    "X = embeddings_matrix\n",
    "y = task_b_df['average_score']\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform cross-validation\n",
    "scores1a = cross_val_score(model1a, X, y, cv=kf, scoring='neg_mean_squared_error')#.round().astype(int)\n",
    "\n",
    "# Since the scores are negative MSE, we might want to convert them to positive MSE\n",
    "mse_scores1a = -scores1a\n",
    "\n",
    "print(\"MSE scores for each fold:\", mse_scores1a)\n",
    "print(\"Average MSE:\", mse_scores1a.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZZJ4APTtHt63"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EUgAdNLdL_69"
   },
   "source": [
    "# 4b. Linear Regression Models (Feature Set 2)\n",
    "*Features include prompt quantifications, such as character count, word count, sentence count, words per sentence, unique words, and unique words to total words ratio*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yzWAHVQSHbgn"
   },
   "source": [
    "**MODEL 2A**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o0lvAsnvzBQE",
    "outputId": "8af7d529-899e-4981-8ceb-fe6c7914d6ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 2.7575698314918027\n"
     ]
    }
   ],
   "source": [
    "# Feature Set 2a **\n",
    "\n",
    "# Feature extraction\n",
    "def extract_features2a(text):\n",
    "    char_count = len(text)\n",
    "    word_count = len(nltk.word_tokenize(text))\n",
    "    char_word_ratio = char_count/word_count\n",
    "    sent_count = len(nltk.sent_tokenize(text))\n",
    "    words_per_sent = word_count / sent_count if sent_count > 0 else 0\n",
    "    uniq_words = len(set(nltk.word_tokenize(text)))\n",
    "    uniq_word_ratio = uniq_words / word_count if word_count > 0 else 0\n",
    "    return [char_count, word_count, char_word_ratio, sent_count, words_per_sent, uniq_words]\n",
    "\n",
    "# Applying feature extraction\n",
    "features2a = merged_df['prompt'].apply(extract_features2a)\n",
    "features2a_df = pd.DataFrame(features2a.tolist(), columns=['char_count', 'word_count', 'char_word_ratio', 'sent_count', 'words_per_sent', 'uniq_words'])\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features2a_df, merged_df['average_score'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Model training\n",
    "model2a = LinearRegression()\n",
    "model2a.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "predictions2a = model2a.predict(X_test).round().astype(int)\n",
    "mse2a = mean_squared_error(y_test, predictions2a)\n",
    "print(\"Mean Squared Error:\", mse2a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M-oTGVvi6C0h"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ICkNQ_EuF-cH"
   },
   "source": [
    "**MODEL 2B**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NJ_BQNg2zOoW",
    "outputId": "ed212a2a-0987-4439-c76e-b228bc222279"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 2.6215573156024905\n"
     ]
    }
   ],
   "source": [
    "# Feature extraction\n",
    "def extract_features2b(text):\n",
    "    char_count = len(text)\n",
    "    word_count = len(nltk.word_tokenize(text))\n",
    "    char_word_ratio = char_count/word_count\n",
    "    sent_count = len(nltk.sent_tokenize(text))\n",
    "    words_per_sent = word_count / sent_count if sent_count > 0 else 0\n",
    "    uniq_words = len(set(nltk.word_tokenize(text)))\n",
    "    uniq_word_ratio = uniq_words / word_count if word_count > 0 else 0\n",
    "    fk_grade = textstat.flesch_kincaid_grade(text) # best\n",
    "    gf_index = textstat.gunning_fog(text)\n",
    "    return [char_count, word_count, char_word_ratio, sent_count, words_per_sent, uniq_words, uniq_word_ratio, fk_grade, gf_index]\n",
    "\n",
    "# Applying feature extraction\n",
    "features2b = merged_df['prompt'].apply(extract_features2b)\n",
    "features2b_df = pd.DataFrame(features2b.tolist(), columns=['char_count', 'word_count', 'char_word_ratio', 'sent_count', 'words_per_sent', 'uniq_words', 'uniq_word_ratio', 'fk_grade', 'gf_index'])\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features2b_df, merged_df['average_score'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Model training\n",
    "model2b = LinearRegression()\n",
    "model2b.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "predictions2b = model2b.predict(X_test).round().astype(int)\n",
    "mse2b = mean_squared_error(y_test, predictions2b)\n",
    "print(\"Mean Squared Error:\", mse2b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P7UrUU096Dmc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TGjFjRM0wqwm"
   },
   "source": [
    "**MODEL 2C**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TvfR6F4gEhhO"
   },
   "source": [
    "Replace fk_grade and gf_index grades with aggregated grade\n",
    "\n",
    "* char_count = textstat.char_count(text)\n",
    "* word_count = textstat.lexicon_count(text, removepunct=True)\n",
    "* sent_count = textstat.sentence_count(text)\n",
    "* words_per_sent = word_count / sent_count if sent_count > 0 else 0\n",
    "* polysyll_count = textstat.polysyllabcount(text)\n",
    "* uniq_words = len(set(word_tokenize(text)))\n",
    "* uniq_word_ratio = uniq_words / word_count if word_count > 0 else 0\n",
    "* grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y9s3hvxSzfGt",
    "outputId": "0c3b89c2-76cf-48e3-8709-10edad8bfb1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 2.6700563866888305\n"
     ]
    }
   ],
   "source": [
    "# Feature extraction\n",
    "def extract_features2c(text):\n",
    "    char_count = textstat.char_count(text)\n",
    "    word_count = textstat.lexicon_count(text, removepunct=True)\n",
    "    sent_count = textstat.sentence_count(text)\n",
    "    words_per_sent = word_count / sent_count if sent_count > 0 else 0\n",
    "    polysyll_count = textstat.polysyllabcount(text)\n",
    "    uniq_words = len(set(word_tokenize(text)))\n",
    "    uniq_word_ratio = uniq_words / word_count if word_count > 0 else 0\n",
    "    grade = textstat.text_standard(text, float_output=True)\n",
    "    return [char_count, word_count, sent_count, words_per_sent, polysyll_count, uniq_words, uniq_word_ratio, grade]#, readability, grade]\n",
    "\n",
    "# Applying feature extraction\n",
    "features2c = merged_df['prompt'].apply(extract_features2c)\n",
    "features2c_df = pd.DataFrame(features2c.tolist(),\n",
    "                            columns=['char_count', 'word_count', 'sent_count', 'words_per_sent',\n",
    "                                     'polysyll_count', 'uniq_words', 'uniq_word_ratio',\n",
    "                                     'complexity'])#, 'readability', 'grade'])\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features2c_df, merged_df['average_score'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Model training\n",
    "model2c = LinearRegression()\n",
    "model2c.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "predictions2c = model2c.predict(X_test).round().astype(int)\n",
    "mse2c = mean_squared_error(y_test, predictions2c)\n",
    "print(\"Mean Squared Error:\", mse2c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u9TLV0nW6FgE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AD8EFFi9r1IS"
   },
   "source": [
    "**MODEL 2D**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XOJF9jYhEkVc"
   },
   "source": [
    "Swap aggregated grade score with just Flesh-Kincaid and Gunning Fog grade-scoring indexes.\n",
    "\n",
    "* char_count\n",
    "* word_count\n",
    "* sent_count\n",
    "* words_per_sent\n",
    "* polysyll_count\n",
    "* uniq_words\n",
    "* uniq_word_ratio\n",
    "* fk_grade\n",
    "* gf_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q5qC69lcz6-X",
    "outputId": "ac99b8ec-d431-4979-ec23-087987d4ab45"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 2.5922232000260754\n"
     ]
    }
   ],
   "source": [
    "# Feature extraction\n",
    "def extract_features2d(text):\n",
    "    char_count = textstat.char_count(text)\n",
    "    word_count = textstat.lexicon_count(text, removepunct=True)\n",
    "    sent_count = textstat.sentence_count(text)\n",
    "    words_per_sent = word_count / sent_count if sent_count > 0 else 0\n",
    "    polysyll_count = textstat.polysyllabcount(text)\n",
    "    uniq_words = len(set(nltk.word_tokenize(text)))\n",
    "    uniq_word_ratio = uniq_words / word_count if word_count > 0 else 0\n",
    "    fk_grade = textstat.flesch_kincaid_grade(text)\n",
    "    gf_index = textstat.gunning_fog(text)\n",
    "    return [char_count, word_count, sent_count, words_per_sent, polysyll_count, uniq_words, uniq_word_ratio, fk_grade, gf_index]\n",
    "\n",
    "# Applying feature extraction\n",
    "features2d = merged_df['prompt'].apply(extract_features2d)\n",
    "features2d_df = pd.DataFrame(features2d.tolist(), columns=['char_count', 'word_count', 'sent_count', 'words_per_sent', 'polysyll_count', 'uniq_words', 'uniq_word_ratio', 'fk_grade', 'gf_index'])\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features2d_df, merged_df['average_score'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Model training\n",
    "model2d = LinearRegression()\n",
    "model2d.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "predictions2d = model2d.predict(X_test).round().astype(int)\n",
    "mse2d = mean_squared_error(y_test, predictions2d)\n",
    "print(\"Mean Squared Error:\", mse2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w_yD4oZa0H31",
    "outputId": "b8312352-233c-4a88-a7e7-a59658be5d20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE scores for each fold: [2.50753503 2.35822615 2.64379417 2.61905511 2.4688373 ]\n",
      "Average MSE: 2.519489551131757\n"
     ]
    }
   ],
   "source": [
    "# 5 K-Fold Cross-Validation\n",
    "\n",
    "X = features2d_df\n",
    "y = merged_df['average_score']\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform cross-validation\n",
    "scores2d = cross_val_score(model2d, X, y, cv=kf, scoring='neg_mean_squared_error')#.round().astype(int)\n",
    "\n",
    "# Since the scores are negative MSE, we might want to convert them to positive MSE\n",
    "mse_scores2d = -scores2d\n",
    "\n",
    "print(\"MSE scores for each fold:\", mse_scores2d)\n",
    "print(\"Average MSE:\", mse_scores2d.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IzTmyb6z6HJ9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "An8QOWZ2KJL0"
   },
   "source": [
    "**MODEL 2E**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ClD5wOJuEonS"
   },
   "source": [
    "Added in read time and complexity (ease score).\n",
    "\n",
    "* char_count\n",
    "* word_count\n",
    "* sent_count\n",
    "* words_per_sent\n",
    "* polysyll_count\n",
    "* uniq_words\n",
    "* uniq_word_ratio\n",
    "* fk_grade\n",
    "* gf_index\n",
    "* read_time\n",
    "* complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Rwoxv1zC0jBJ",
    "outputId": "385e530e-7bbb-42d1-db8c-e6f8f9e1d620"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 2.596427756592028\n"
     ]
    }
   ],
   "source": [
    "# Feature extraction\n",
    "def extract_features2e(text):\n",
    "    char_count = textstat.char_count(text)\n",
    "    word_count = textstat.lexicon_count(text, removepunct=True)\n",
    "    sent_count = textstat.sentence_count(text)\n",
    "    words_per_sent = word_count / sent_count if sent_count > 0 else 0\n",
    "    polysyll_count = textstat.polysyllabcount(text)\n",
    "    uniq_words = len(set(nltk.word_tokenize(text)))\n",
    "    uniq_word_ratio = uniq_words / word_count if word_count > 0 else 0\n",
    "    fk_grade = textstat.flesch_kincaid_grade(text)\n",
    "    gf_index = textstat.gunning_fog(text)\n",
    "    read_time = textstat.reading_time(text, ms_per_char=14.69)\n",
    "    complexity = textstat.flesch_reading_ease(text)\n",
    "    return [char_count, word_count, sent_count, words_per_sent, polysyll_count, uniq_words, uniq_word_ratio, fk_grade, gf_index, read_time, complexity]\n",
    "\n",
    "# Applying feature extraction\n",
    "features2e = merged_df['prompt'].apply(extract_features2e)\n",
    "features2e_df = pd.DataFrame(features2e.tolist(), columns=['char_count', 'word_count', 'sent_count', 'words_per_sent',\n",
    "                                                         'polysyll_count', 'uniq_words', 'uniq_word_ratio',\n",
    "                                                         'fk_grade', 'gf_index', 'readability', 'complexity'])\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features2e_df, merged_df['average_score'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Model training\n",
    "model2e = LinearRegression()\n",
    "model2e.fit(X_train, y_train)\n",
    "\n",
    "predictions2e = model2e.predict(X_test).round().astype(int)\n",
    "mse2e = mean_squared_error(y_test, predictions2e)\n",
    "print(\"Mean Squared Error:\", mse2e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DyNrrwqkNvH-",
    "outputId": "6a68f890-6ac9-468e-a7db-bf499db681d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE scores for each fold: [2.49638352 2.32532891 2.6244671  2.600004   2.44309104]\n",
      "Average MSE: 2.4978549123404905\n"
     ]
    }
   ],
   "source": [
    "# 5 K-Fold Cross-Validation\n",
    "\n",
    "X = features2e_df\n",
    "y = merged_df['average_score']\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform cross-validation\n",
    "scores2e = cross_val_score(model2e, X, y, cv=kf, scoring='neg_mean_squared_error')#.round().astype(int)\n",
    "\n",
    "# Since the scores are negative MSE, we might want to convert them to positive MSE\n",
    "mse_scores2e = -scores2e\n",
    "\n",
    "print(\"MSE scores for each fold:\", mse_scores2e)\n",
    "print(\"Average MSE:\", mse_scores2e.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x5dWTKCFkzkB"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R9ur1uSekmw2"
   },
   "source": [
    "## 4c. Linear Regression Models (Feature Set 3)\n",
    "*Features include combinations of prompt quantifications and embeddings*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q9jvznrU6MUa"
   },
   "source": [
    "**MODEL 3A**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rcAXRwlAw9Zh",
    "outputId": "d50f9a70-da8d-4ccf-d58f-96ed4fff4721"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 2.048665837135352\n"
     ]
    }
   ],
   "source": [
    "# Feature extraction\n",
    "def extract_features3a(text):\n",
    "    char_count = len(text)\n",
    "    word_count = len(nltk.word_tokenize(text))\n",
    "    char_word_ratio = char_count/word_count\n",
    "    sent_count = len(nltk.sent_tokenize(text))\n",
    "    words_per_sent = word_count / sent_count if sent_count > 0 else 0\n",
    "    uniq_words = len(set(nltk.word_tokenize(text)))\n",
    "    uniq_word_ratio = uniq_words / word_count if word_count > 0 else 0\n",
    "    return [char_count, word_count, char_word_ratio, sent_count, words_per_sent, uniq_words]\n",
    "\n",
    "# Applying feature extraction\n",
    "features3a = task_b_df['prompt'].apply(extract_features3a)\n",
    "features3a_df = pd.DataFrame(features3a.tolist(), columns=['char_count', 'word_count', 'char_word_ratio', 'sent_count', 'words_per_sent', 'uniq_words'])\n",
    "\n",
    "# Reset the indices of both DataFrames if the indices do not matter\n",
    "features3a_df = features3a_df.reset_index(drop=True)\n",
    "\n",
    "# Add embeddings to features\n",
    "features3a_df = pd.concat([features3a_df, embeddings_matrix], axis=1)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features3a_df, task_b_df['average_score'], test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Model training\n",
    "model3a = LinearRegression()\n",
    "model3a.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "predictions3a = model3a.predict(X_test).round().astype(int)\n",
    "mse3a = mean_squared_error(y_test, predictions3a)\n",
    "print(\"Mean Squared Error:\", mse3a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DqASXt5ucrsO",
    "outputId": "9f05448f-30a3-48e5-dc26-fa114f1a9186"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE scores for each fold: [1.9632777  1.94913748 1.91231589 1.86523687 1.96537674]\n",
      "Average MSE: 1.9310689356872133\n"
     ]
    }
   ],
   "source": [
    "# NEW FEATURE SET 3a (prompt-text + embeddings)\n",
    "\n",
    "# 5 K-Fold Cross-Validation\n",
    "\n",
    "X = features3a_df\n",
    "y = task_b_df['average_score']\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform cross-validation\n",
    "scores3a = cross_val_score(model3a, X, y, cv=kf, scoring='neg_mean_squared_error')#.round().astype(int)\n",
    "\n",
    "# Since the scores are negative MSE, we might want to convert them to positive MSE\n",
    "mse3a_scores = -scores3a\n",
    "\n",
    "print(\"MSE scores for each fold:\", mse3a_scores)\n",
    "print(\"Average MSE:\", mse3a_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LXJgYrKM6TBb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Esb1PlYI6TqN"
   },
   "source": [
    "**MODEL 3B**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HeiBgNU1hnIG",
    "outputId": "36fb571d-b7cc-469d-9b37-5c5fe5c45a2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 1.9937093875293788\n"
     ]
    }
   ],
   "source": [
    "# Feature extraction\n",
    "def extract_features3b(text):\n",
    "    char_count = textstat.char_count(text)\n",
    "    word_count = textstat.lexicon_count(text, removepunct=True)\n",
    "    sent_count = textstat.sentence_count(text) # not used in actual feature set\n",
    "    words_per_sent = word_count / sent_count if sent_count > 0 else 0\n",
    "    polysyll_count = textstat.polysyllabcount(text)\n",
    "    uniq_words = len(set(nltk.word_tokenize(text)))\n",
    "    uniq_word_ratio = uniq_words / word_count if word_count > 0 else 0\n",
    "    fk_grade = textstat.flesch_kincaid_grade(text)\n",
    "    gf_index = textstat.gunning_fog(text)\n",
    "    return [char_count, word_count, sent_count, words_per_sent, polysyll_count, uniq_words, uniq_word_ratio, fk_grade, gf_index]\n",
    "\n",
    "# Applying feature extraction\n",
    "features3b = task_b_df['prompt'].apply(extract_features3b)\n",
    "features3b_df = pd.DataFrame(features3b.tolist(), columns=['char_count', 'word_count', 'sent_count', 'words_per_sent', 'polysyll_count', 'uniq_words', 'uniq_word_ratio', 'fk_grade', 'gf_index'])\n",
    "\n",
    "# Reset the indices of both DataFrames if the indices do not matter\n",
    "features3b_df = features3b_df.reset_index(drop=True)\n",
    "# Add embeddings\n",
    "features3b_df = pd.concat([features3b_df, embeddings_matrix], axis=1)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features3b_df, task_b_df['average_score'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Model training\n",
    "model3b = LinearRegression()\n",
    "model3b.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "predictions3b = model3b.predict(X_test).round().astype(int)\n",
    "mse3b = mean_squared_error(y_test, predictions3b)\n",
    "print(\"Mean Squared Error:\", mse3b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yuopk5tKhgZP",
    "outputId": "23d277bd-da79-4aab-f9b5-be63cb3fb471"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE scores for each fold: [1.92853675 1.91495744 1.87101823 1.82742731 1.94645616]\n",
      "Average MSE: 1.8976791779644326\n"
     ]
    }
   ],
   "source": [
    "# Feature Set 3b (prompt-text + complexity + embeddings)\n",
    "\n",
    "# 5 K-Fold Cross-Validation\n",
    "\n",
    "X = features3b_df\n",
    "y = task_b_df['average_score']\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform cross-validation\n",
    "scores3b = cross_val_score(model3b, X, y, cv=kf, scoring='neg_mean_squared_error')#.round().astype(int)\n",
    "\n",
    "# Since the scores are negative MSE, we might want to convert them to positive MSE\n",
    "mse3b_scores = -scores3b\n",
    "\n",
    "print(\"MSE scores for each fold:\", mse3b_scores)\n",
    "print(\"Average MSE:\", mse3b_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3qUwjUIP6YCp"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e_M_DtWr6YRk"
   },
   "source": [
    "**MODEL 3C**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A3613R3Si7IN",
    "outputId": "00a92b62-8b4c-43b1-ebb6-1c31d5b086b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 1.9789852066915528\n"
     ]
    }
   ],
   "source": [
    "# Feature extraction\n",
    "def extract_features3c(text):\n",
    "    char_count = textstat.char_count(text)\n",
    "    word_count = textstat.lexicon_count(text, removepunct=True)\n",
    "    sent_count = textstat.sentence_count(text)\n",
    "    words_per_sent = word_count / sent_count if sent_count > 0 else 0\n",
    "    polysyll_count = textstat.polysyllabcount(text)\n",
    "    uniq_words = len(set(nltk.word_tokenize(text)))\n",
    "    uniq_word_ratio = uniq_words / word_count if word_count > 0 else 0\n",
    "    fk_grade = textstat.flesch_kincaid_grade(text)\n",
    "    gf_index = textstat.gunning_fog(text)\n",
    "    read_time = textstat.reading_time(text, ms_per_char=14.69)\n",
    "    complexity = textstat.flesch_reading_ease(text)\n",
    "    return [char_count, word_count, sent_count, words_per_sent, polysyll_count, uniq_words, uniq_word_ratio, fk_grade, gf_index, read_time, complexity]\n",
    "\n",
    "# Applying feature extraction\n",
    "features3c = task_b_df['prompt'].apply(extract_features3c)\n",
    "features3c_df = pd.DataFrame(features3c.tolist(), columns=['char_count', 'word_count', 'sent_count', 'words_per_sent',\n",
    "                                                         'polysyll_count', 'uniq_words', 'uniq_word_ratio',\n",
    "                                                         'fk_grade', 'gf_index', 'readability', 'complexity'])\n",
    "\n",
    "# Reset the indices of both DataFrames if the indices do not matter\n",
    "features3c_df = features3c_df.reset_index(drop=True)\n",
    "\n",
    "# Add embeddings to feature set\n",
    "features3c_df = pd.concat([features3c_df, embeddings_matrix], axis=1)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features3c_df, task_b_df['average_score'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Model training\n",
    "model3c = LinearRegression()\n",
    "model3c.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "predictions3c = model3c.predict(X_test).round().astype(int)\n",
    "mse3c = mean_squared_error(y_test, predictions3c)\n",
    "print(\"Mean Squared Error:\", mse3c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WN2HAhjjjHez",
    "outputId": "2da5497f-5d7e-4b27-d7e5-d2feba9d9f46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE scores for each fold: [1.91947672 1.90859222 1.86790831 1.82232856 1.93217564]\n",
      "Average MSE: 1.8900962904055025\n"
     ]
    }
   ],
   "source": [
    "# Feature Set 3c (prompt-text + complexity + embeddings)\n",
    "\n",
    "# 5 K-Fold Cross-Validation\n",
    "\n",
    "X = features3c_df\n",
    "y = task_b_df['average_score']\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform cross-validation\n",
    "scores3c = cross_val_score(model3c, X, y, cv=kf, scoring='neg_mean_squared_error')#.round().astype(int)\n",
    "\n",
    "# Since the scores are negative MSE, we might want to convert them to positive MSE\n",
    "mse3c_scores = -scores3c\n",
    "\n",
    "print(\"MSE scores for each fold:\", mse3c_scores)\n",
    "print(\"Average MSE:\", mse3c_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fv0HpDUUk2bl"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ZjwY6ztJM_2"
   },
   "source": [
    "# **5. Test on Validation Dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lkdaZtA2WZfD"
   },
   "source": [
    "## 5a. Import & Clean Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 98
    },
    "id": "UZ2h7VhYJdzb",
    "outputId": "9885ea38-8900-4001-c473-18aa720100af"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>prompt</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4f332ebd8cdc4ff2be74aa8828ff20d5</td>\n",
       "      <td>what do you think about the future of iran?</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>vicuna-13b</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        question_id  \\\n",
       "0  4f332ebd8cdc4ff2be74aa8828ff20d5   \n",
       "\n",
       "                                        prompt    model_a     model_b  \n",
       "0  what do you think about the future of iran?  koala-13b  vicuna-13b  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(3206, 4)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import validation set prompts\n",
    "\n",
    "# Set URL of the validation prompts JSON\n",
    "validation_prompts_url = \"https://raw.githubusercontent.com/dychenster/nlp-chatarena/main/arena-validation-set-prompt-only.jsonl.gz\"\n",
    "\n",
    "# Read prompts JSON file into a DataFrame\n",
    "validation_prompts = pd.read_json(validation_prompts_url, lines=True)\n",
    "\n",
    "# Display the first row of the data\n",
    "display(validation_prompts.head(1))\n",
    "display(validation_prompts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 98
    },
    "id": "gwqSyhT9KZ9q",
    "outputId": "c96d4b97-0be2-42e4-c83c-7c35ebb8e0c0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>prompt</th>\n",
       "      <th>topic_modeling_1</th>\n",
       "      <th>topic_modeling_2</th>\n",
       "      <th>topic_modeling_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4f332ebd8cdc4ff2be74aa8828ff20d5</td>\n",
       "      <td>what do you think about the future of iran?</td>\n",
       "      <td>Future Prediction</td>\n",
       "      <td>Future Prediction</td>\n",
       "      <td>Future Prediction</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        question_id  \\\n",
       "0  4f332ebd8cdc4ff2be74aa8828ff20d5   \n",
       "\n",
       "                                        prompt   topic_modeling_1  \\\n",
       "0  what do you think about the future of iran?  Future Prediction   \n",
       "\n",
       "    topic_modeling_2   topic_modeling_3  \n",
       "0  Future Prediction  Future Prediction  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(3206, 5)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import validation set - topics\n",
    "\n",
    "# Set URL of the validation topics JSON\n",
    "validation_topics_url = \"https://raw.githubusercontent.com/dychenster/nlp-chatarena/main/arena-validation-set-topic-modeling.jsonl.gz\"\n",
    "\n",
    "# Read topics JSON file into a DataFrame\n",
    "validation_topics = pd.read_json(validation_topics_url, lines=True)\n",
    "\n",
    "# Display the first row of the data\n",
    "display(validation_topics.head(1))\n",
    "display(validation_topics.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b8MKrPhKAPLX",
    "outputId": "a7612ae3-f4c6-4457-d505-c63b84a05bbc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings loaded successfully into Colab.\n"
     ]
    }
   ],
   "source": [
    "# Import validation set - embeddings\n",
    "\n",
    "# Set URL of the validation embeddings JSON\n",
    "validation_embeddings_url = \"https://raw.githubusercontent.com/dychenster/nlp-chatarena/main/arena-validation-set-prompts-embeddings.npy\"\n",
    "\n",
    "# Use requests to get the file content\n",
    "response_val = requests.get(validation_embeddings_url)\n",
    "\n",
    "# Make sure the request was successful\n",
    "if response_val.status_code == 200:\n",
    "    # Load the content into a numpy array\n",
    "    validation_content = BytesIO(response_val.content)\n",
    "    validation_embeddings = np.load(validation_content)\n",
    "    print(\"Embeddings loaded successfully into Colab.\")\n",
    "else:\n",
    "    print(f\"Failed to load the file. Status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7tP5uMewBLFQ",
    "outputId": "0c0cee08-72e6-4294-8286-42dbbab8c376"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3206, 256)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_embeddings_df = pd.DataFrame(validation_embeddings, columns=[f'e_{i}' for i in range(256)])\n",
    "print('The validation embeddings df has a shape of:', val_embeddings_df.shape) # (3206, 256)\n",
    "\n",
    "validation_df = validation_prompts.merge(validation_topics, on=\"question_id\")\n",
    "print('The merged validation prompts and topics df has a shape of:', validation_df.shape) # (3208, 8)\n",
    "\n",
    "# CHECK FOR DUPLICATES\n",
    "print('The merged validation prompts and topics df has a shape of:', validation_prompts['question_id'].duplicated().sum())\n",
    "print('The merged validation prompts and topics df has a shape of:', validation_topics['question_id'].duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NEntN1Z1NI36",
    "outputId": "57482933-db0d-4db5-fce1-0e6263c6f93a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate rows in validation_prompts based on question_id:\n",
      "                           question_id  \\\n",
      "2527  08003723f24740a6bdb547a10e70cad9   \n",
      "2528  08003723f24740a6bdb547a10e70cad9   \n",
      "\n",
      "                                                 prompt           model_a  \\\n",
      "2527  Wonderful. You must NEVER break character. You...  RWKV-4-Raven-14B   \n",
      "2528  Wonderful. You must NEVER break character. You...  RWKV-4-Raven-14B   \n",
      "\n",
      "                model_b  \n",
      "2527  claude-instant-v1  \n",
      "2528  claude-instant-v1  \n",
      "\n",
      "Duplicate rows in validation_topics based on question_id:\n",
      "                           question_id  \\\n",
      "2527  08003723f24740a6bdb547a10e70cad9   \n",
      "2528  08003723f24740a6bdb547a10e70cad9   \n",
      "\n",
      "                                                 prompt  \\\n",
      "2527  Wonderful. You must NEVER break character. You...   \n",
      "2528  Wonderful. You must NEVER break character. You...   \n",
      "\n",
      "             topic_modeling_1         topic_modeling_2    topic_modeling_3  \n",
      "2527  Creativity, Imagination  imagination, creativity  Improv Performance  \n",
      "2528            Improv Comedy    Creative Role-playing   Improv Creativity  \n"
     ]
    }
   ],
   "source": [
    "# CLEAN DUPLICATES\n",
    "\n",
    "# Identify duplicate rows in the 'validation_prompts' DataFrame\n",
    "duplicate_prompts = validation_prompts[validation_prompts.duplicated(subset='question_id', keep=False)]\n",
    "\n",
    "# Identify duplicate rows in the 'validation_topics' DataFrame\n",
    "duplicate_topics = validation_topics[validation_topics.duplicated(subset='question_id', keep=False)]\n",
    "\n",
    "# Display the duplicate rows\n",
    "print(\"Duplicate rows in validation_prompts based on question_id:\")\n",
    "print(duplicate_prompts)\n",
    "\n",
    "print(\"\\nDuplicate rows in validation_topics based on question_id:\")\n",
    "print(duplicate_topics)\n",
    "\n",
    "# Add a column to mark the first two duplicates\n",
    "validation_df['duplicate_count'] = validation_df.groupby('question_id').cumcount()\n",
    "\n",
    "# Keep only the first two duplicates (i.e., where duplicate_count is 0 or 1)\n",
    "validation_df_filtered = validation_df[validation_df['duplicate_count'] < 2].copy()\n",
    "\n",
    "# Now drop the 'duplicate_count' column as it's no longer needed\n",
    "validation_df_filtered.drop('duplicate_count', axis=1, inplace=True)\n",
    "\n",
    "# Verify the result\n",
    "print(validation_df_filtered.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 310
    },
    "id": "sdFe12ChWeb1",
    "outputId": "0dc60950-08f7-4889-8284-0d11688032ea"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>prompt</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>topic_modeling_1</th>\n",
       "      <th>topic_modeling_2</th>\n",
       "      <th>topic_modeling_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4f332ebd8cdc4ff2be74aa8828ff20d5</td>\n",
       "      <td>what do you think about the future of iran?</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>vicuna-13b</td>\n",
       "      <td>Future Prediction</td>\n",
       "      <td>Future Prediction</td>\n",
       "      <td>Future Prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f2be6f13e5ed40e5b81443223996494c</td>\n",
       "      <td>Salut ! Tu es un méchant chatbot !</td>\n",
       "      <td>stablelm-tuned-alpha-7b</td>\n",
       "      <td>vicuna-13b</td>\n",
       "      <td>Role-playing, Evaluation</td>\n",
       "      <td>Role-play, Evaluation</td>\n",
       "      <td>Creativity, Factual Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5fafefb8a0c54243afb52d2892946cea</td>\n",
       "      <td>⚔️ Chatbot Arena ⚔️\\nRules:\\n    Chat with two...</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>vicuna-13b</td>\n",
       "      <td>Chatbot Evaluation</td>\n",
       "      <td>Chatbot Evaluation</td>\n",
       "      <td>Chatbot Evaluation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7834f572267f40709ecebb273a2b346b</td>\n",
       "      <td>Guess the word that i have in my mind</td>\n",
       "      <td>chatglm-6b</td>\n",
       "      <td>stablelm-tuned-alpha-7b</td>\n",
       "      <td>Guessing Game</td>\n",
       "      <td>Word Guessing</td>\n",
       "      <td>Word Guessing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1ccc7e58290245c4bd5457fce45f8640</td>\n",
       "      <td>You are a peasant living in the village. But s...</td>\n",
       "      <td>vicuna-13b</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>Problem-Solving, Creativity</td>\n",
       "      <td>Problem Solving</td>\n",
       "      <td>Problem-solving, Creativity</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        question_id  \\\n",
       "0  4f332ebd8cdc4ff2be74aa8828ff20d5   \n",
       "1  f2be6f13e5ed40e5b81443223996494c   \n",
       "2  5fafefb8a0c54243afb52d2892946cea   \n",
       "3  7834f572267f40709ecebb273a2b346b   \n",
       "4  1ccc7e58290245c4bd5457fce45f8640   \n",
       "\n",
       "                                              prompt                  model_a  \\\n",
       "0        what do you think about the future of iran?                koala-13b   \n",
       "1                 Salut ! Tu es un méchant chatbot !  stablelm-tuned-alpha-7b   \n",
       "2  ⚔️ Chatbot Arena ⚔️\\nRules:\\n    Chat with two...                koala-13b   \n",
       "3              Guess the word that i have in my mind               chatglm-6b   \n",
       "4  You are a peasant living in the village. But s...               vicuna-13b   \n",
       "\n",
       "                   model_b             topic_modeling_1  \\\n",
       "0               vicuna-13b            Future Prediction   \n",
       "1               vicuna-13b     Role-playing, Evaluation   \n",
       "2               vicuna-13b           Chatbot Evaluation   \n",
       "3  stablelm-tuned-alpha-7b                Guessing Game   \n",
       "4                koala-13b  Problem-Solving, Creativity   \n",
       "\n",
       "        topic_modeling_2              topic_modeling_3  \n",
       "0      Future Prediction             Future Prediction  \n",
       "1  Role-play, Evaluation  Creativity, Factual Accuracy  \n",
       "2     Chatbot Evaluation            Chatbot Evaluation  \n",
       "3          Word Guessing                 Word Guessing  \n",
       "4        Problem Solving   Problem-solving, Creativity  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_df_filtered.drop(columns=[\"prompt_y\"], inplace=True)\n",
    "validation_df_filtered.rename(columns = {\"prompt_x\":\"prompt\"}, inplace=True)\n",
    "validation_df_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FdX-2GRj8n2T"
   },
   "source": [
    "## 5b. Test Models Using Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "71HGhr-i3c7l"
   },
   "outputs": [],
   "source": [
    "# Validation Distribution for Reference\n",
    "\n",
    "# hardness_score\n",
    "# 1     204\n",
    "# 2     377\n",
    "# 3      87\n",
    "# 4      74\n",
    "# 5     189\n",
    "# 6     182\n",
    "# 7    1087\n",
    "# 8     913\n",
    "# 9      93\n",
    "# Name: count, dtype: int64\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VtMYPwBMWAX1"
   },
   "source": [
    "**TASK A PREDICTIONS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "5VtnSde8pr5U"
   },
   "outputs": [],
   "source": [
    "# Create dataframe for Task A testing\n",
    "\n",
    "task_a_val_df = validation_df_filtered.copy()\n",
    "\n",
    "task_a_val_df[\"prompt_length\"] = task_a_val_df[\"prompt\"].str.len()\n",
    "task_a_val_df[\"prompt_complexity\"] = (task_a_val_df[\"prompt\"]).apply(textstat.flesch_reading_ease)\n",
    "task_a_val_df[\"prompt_grade\"] = task_a_val_df[\"prompt\"].apply(lambda x: textstat.text_standard(x, float_output=True))\n",
    "task_a_val_df[\"prompt_time\"] = task_a_val_df[\"prompt\"].apply(lambda x: textstat.reading_time(x, ms_per_char=14.69))\n",
    "\n",
    "# ADDED\n",
    "# Add model win rate column\n",
    "task_a_val_df[\"model_a_win_rate\"] = task_a_val_df[\"model_a\"].map(win_rates)\n",
    "task_a_val_df[\"model_b_win_rate\"] = task_a_val_df[\"model_b\"].map(win_rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode models\n",
    "print(models_combined)\n",
    "\n",
    "# Initialize the columns to zero\n",
    "for model in models_combined:\n",
    "    task_a_val_df[model] = 0\n",
    "\n",
    "# Use logical OR to combine the one-hot encoding for both model_a and model_b\n",
    "for model in models_combined:\n",
    "    task_a_val_df[model] = ((task_a_df[\"model_a\"] == model) | (task_a_df[\"model_b\"] == model)).astype(int)\n",
    "\n",
    "# Check OHE columns\n",
    "task_a_val_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "nX7qJO47WFIP"
   },
   "outputs": [],
   "source": [
    "# Set test features\n",
    "X_validation = task_a_val_df[features]\n",
    "\n",
    "# Create predictions\n",
    "y_validation_pred_encoded = model_task_a.predict(X_validation)\n",
    "\n",
    "# Decode the predictions back to the original labels\n",
    "winner_predictions = le.inverse_transform(y_validation_pred_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X6se8ARF439e"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0reEzFqAE1ur"
   },
   "source": [
    "**TASK B PREDICTIONS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 981
    },
    "id": "yNqNfPJWInAw",
    "outputId": "1c0ac30e-be15-496f-93aa-5c46c731a674"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>prompt</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>topic_modeling_1</th>\n",
       "      <th>topic_modeling_2</th>\n",
       "      <th>topic_modeling_3</th>\n",
       "      <th>e_0</th>\n",
       "      <th>e_1</th>\n",
       "      <th>e_2</th>\n",
       "      <th>...</th>\n",
       "      <th>e_246</th>\n",
       "      <th>e_247</th>\n",
       "      <th>e_248</th>\n",
       "      <th>e_249</th>\n",
       "      <th>e_250</th>\n",
       "      <th>e_251</th>\n",
       "      <th>e_252</th>\n",
       "      <th>e_253</th>\n",
       "      <th>e_254</th>\n",
       "      <th>e_255</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4f332ebd8cdc4ff2be74aa8828ff20d5</td>\n",
       "      <td>what do you think about the future of iran?</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>vicuna-13b</td>\n",
       "      <td>Future Prediction</td>\n",
       "      <td>Future Prediction</td>\n",
       "      <td>Future Prediction</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>-0.12</td>\n",
       "      <td>0.06</td>\n",
       "      <td>...</td>\n",
       "      <td>0.04</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>-0.06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 263 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        question_id  \\\n",
       "0  4f332ebd8cdc4ff2be74aa8828ff20d5   \n",
       "\n",
       "                                        prompt    model_a     model_b  \\\n",
       "0  what do you think about the future of iran?  koala-13b  vicuna-13b   \n",
       "\n",
       "    topic_modeling_1   topic_modeling_2   topic_modeling_3   e_0   e_1  e_2  \\\n",
       "0  Future Prediction  Future Prediction  Future Prediction -0.06 -0.12 0.06   \n",
       "\n",
       "   ...  e_246  e_247  e_248  e_249  e_250  e_251  e_252  e_253  e_254  e_255  \n",
       "0  ...   0.04  -0.04   0.04   0.00  -0.08   0.00   0.01  -0.02  -0.03  -0.06  \n",
       "\n",
       "[1 rows x 263 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create dataframe for Task B testing\n",
    "task_b_val_df = validation_df_filtered.copy()\n",
    "\n",
    "# Add embeddings\n",
    "task_b_val_df.reset_index(drop=True, inplace=True)\n",
    "val_embeddings_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "task_b_val_df = pd.concat([task_b_val_df, val_embeddings_df], axis=1)\n",
    "task_b_val_df.head(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Examine variability in model performance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_4MtChVW-2Hx",
    "outputId": "6ab48367-57b0-4adb-cfe9-dc637cc390b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Hardness Score: 6\n"
     ]
    }
   ],
   "source": [
    "# TEST MODEL 1A\n",
    "\n",
    "# Predict and evaluate\n",
    "val_predictions1a = model1a.predict(val_embeddings_df).astype(int)\n",
    "# print(\"Predicted Hardness Score:\", val_predictions1a[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bYHBvI0zPaeR",
    "outputId": "b6841395-20c8-4783-9027-119426b1ea76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Hardness Score: 7\n"
     ]
    }
   ],
   "source": [
    "# TEST MODEL 2D\n",
    "\n",
    "# Applying feature extraction\n",
    "val_features2d = task_b_val_df['prompt'].apply(extract_features2d)\n",
    "val_features2d_df = pd.DataFrame(val_features2d.tolist(), columns=['char_count', 'word_count', 'sent_count', 'words_per_sent', 'polysyll_count', 'uniq_words', 'uniq_word_ratio', 'fk_grade', 'gf_index'])\n",
    "\n",
    "# Reset the indices of both DataFrames if the indices do not matter\n",
    "val_features2d_df = val_features2d_df.reset_index(drop=True)\n",
    "\n",
    "# Predict and evaluate\n",
    "val_predictions2d = model2d.predict(val_features2d_df).round().astype(int)\n",
    "# print(\"Predicted Hardness Score:\", val_predictions2d[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CZSHuO_3IzsJ",
    "outputId": "f2227387-5e82-4b4e-aa7c-e222cc1d0c0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Hardness Score: 7\n"
     ]
    }
   ],
   "source": [
    "# TEST MODEL 2E\n",
    "\n",
    "# Applying feature extraction\n",
    "val_features2e = task_b_val_df['prompt'].apply(extract_features2e)\n",
    "val_features2e_df = pd.DataFrame(val_features2e.tolist(), columns=['char_count', 'word_count', 'sent_count', 'words_per_sent',\n",
    "                                                         'polysyll_count', 'uniq_words', 'uniq_word_ratio',\n",
    "                                                         'fk_grade', 'gf_index', 'readability', 'complexity'])\n",
    "\n",
    "# Reset the indices of both DataFrames if the indices do not matter\n",
    "val_features2e_df = val_features2e_df.reset_index(drop=True)\n",
    "\n",
    "# Predict and evaluate\n",
    "val_predictions2e = model2e.predict(val_features2e_df).round().astype(int)\n",
    "# print(\"Predicted Hardness Score:\", val_predictions2e[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4Zn-uF6qE0lJ",
    "outputId": "90aad155-9c94-4be3-8c9d-3e1d01a142f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Hardness Score: 6\n"
     ]
    }
   ],
   "source": [
    "# TEST MODEL 3A\n",
    "\n",
    "# Applying feature extraction\n",
    "val_features3a = task_b_val_df['prompt'].apply(extract_features3a)\n",
    "val_features3a_df = pd.DataFrame(val_features3a.tolist(), columns=['char_count', 'word_count', 'char_word_ratio', 'sent_count', 'words_per_sent', 'uniq_words'])\n",
    "\n",
    "# Reset the indices of both DataFrames if the indices do not matter\n",
    "val_features3a_df = val_features3a_df.reset_index(drop=True)\n",
    "\n",
    "val_features3a_df = pd.concat([val_features3a_df, val_embeddings_df], axis=1)\n",
    "\n",
    "# Predict and evaluate\n",
    "val_predictions3a = model3a.predict(val_features3a_df).astype(int)\n",
    "# print(\"Predicted Hardness Score:\", val_predictions3a[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Th9VkmTewxhK",
    "outputId": "623bfd1f-7570-4951-d699-24386de8fe49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Hardness Score: 7\n"
     ]
    }
   ],
   "source": [
    "# TEST MODEL 3C\n",
    "\n",
    "# Applying feature extraction\n",
    "val_features3c = task_b_val_df['prompt'].apply(extract_features3c)\n",
    "val_features3c_df = pd.DataFrame(val_features3c.tolist(), columns=['char_count', 'word_count', 'sent_count', 'words_per_sent',\n",
    "                                                         'polysyll_count', 'uniq_words', 'uniq_word_ratio',\n",
    "                                                         'fk_grade', 'gf_index', 'readability', 'complexity'])\n",
    "\n",
    "# Reset the indices of both DataFrames if the indices do not matter\n",
    "val_features3c_df = val_features3c_df.reset_index(drop=True)\n",
    "# Add embeddings\n",
    "val_features3c_df = pd.concat([val_features3c_df, val_embeddings_df], axis=1)\n",
    "\n",
    "# Predict and evaluate\n",
    "val_predictions3c = model3c.predict(val_features3c_df).round().astype(int)\n",
    "# print(\"Predicted Hardness Score:\", val_predictions3c[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vp1y-_RP_WBd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Eq4sonQ5QlSO"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3LCH7SwVpsib"
   },
   "source": [
    "# **6. Create CSV for Download**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import FileLink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='submission1a.csv' target='_blank'>submission1a.csv</a><br>"
      ],
      "text/plain": [
       "/Users/dianachen/Desktop/3039626046_3039579441/submission1a.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# MODEL 1A PREDICTIONS\n",
    "\n",
    "# Create DataFrame with specified columns\n",
    "submission1a_df = pd.DataFrame({\n",
    "    'question_id': validation_df_filtered['question_id'],\n",
    "    'winner': winner_predictions, # list or array of winners\n",
    "    'hardness_score': val_predictions1a},\n",
    "    columns=['question_id', 'winner', 'hardness_score'])\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "submission1a_df.to_csv('submission1a.csv', index=False)\n",
    "\n",
    "# Provide a link to download the file\n",
    "display(FileLink('submission1a.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='submission2d.csv' target='_blank'>submission2d.csv</a><br>"
      ],
      "text/plain": [
       "/Users/dianachen/Desktop/3039626046_3039579441/submission2d.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# MODEL 2D PREDICTIONS\n",
    "\n",
    "# Create DataFrame with specified columns\n",
    "submission2d_df = pd.DataFrame({\n",
    "    'question_id': validation_df_filtered['question_id'],\n",
    "    'winner': winner_predictions, # list or array of winners\n",
    "    'hardness_score': val_predictions2d},\n",
    "    columns=['question_id', 'winner', 'hardness_score'])\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "submission2d_df.to_csv('submission2d.csv', index=False)\n",
    "\n",
    "# Provide a link to download the file\n",
    "display(FileLink('submission2d.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='submission2e.csv' target='_blank'>submission2e.csv</a><br>"
      ],
      "text/plain": [
       "/Users/dianachen/Desktop/3039626046_3039579441/submission2e.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# MODEL 2E PREDICTIONS\n",
    "\n",
    "# Create DataFrame with specified columns\n",
    "submission2e_df = pd.DataFrame({\n",
    "    'question_id': validation_df_filtered['question_id'],\n",
    "    'winner': winner_predictions, # list or array of winners\n",
    "    'hardness_score': val_predictions2e},\n",
    "    columns=['question_id', 'winner', 'hardness_score'])\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "submission2e_df.to_csv('submission2e.csv', index=False)\n",
    "\n",
    "# Provide a link to download the file\n",
    "display(FileLink('submission2e.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "XkmF9yDDQ5y0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='submission3a.csv' target='_blank'>submission3a.csv</a><br>"
      ],
      "text/plain": [
       "/Users/dianachen/Desktop/3039626046_3039579441/submission3a.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# MODEL 3A PREDICTIONS\n",
    "\n",
    "# Create DataFrame with specified columns\n",
    "submission3a_df = pd.DataFrame({\n",
    "    'question_id': validation_df_filtered['question_id'],\n",
    "    'winner': winner_predictions, # list or array of winners\n",
    "    'hardness_score': val_predictions3a},\n",
    "    columns=['question_id', 'winner', 'hardness_score'])\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "submission3a_df.to_csv('submission3a.csv', index=False)\n",
    "\n",
    "# Provide a link to download the file\n",
    "display(FileLink('submission3a.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "k3OsthlhkMek",
    "outputId": "9d3677b9-65b6-4c49-dea9-be186a007620"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='submission3c.csv' target='_blank'>submission3c.csv</a><br>"
      ],
      "text/plain": [
       "/Users/dianachen/Desktop/3039626046_3039579441/submission3c.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# MODEL 3C PREDICTIONS\n",
    "\n",
    "# Create DataFrame with specified columns\n",
    "submission3c_df = pd.DataFrame({\n",
    "    'question_id': validation_df_filtered['question_id'],\n",
    "    'winner': winner_predictions, # list or array of winners\n",
    "    'hardness_score': val_predictions3c},\n",
    "    columns=['question_id', 'winner', 'hardness_score'])\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "submission3c_df.to_csv('submission3c.csv', index=False)\n",
    "\n",
    "# Provide a link to download the file\n",
    "display(FileLink('submission3c.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0M3J2hmHoO9J"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "17e_GGrM4Zv6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***References:***\n",
    "\n",
    "[1] N. Mehrabi, F. Morstatter, N. Saxena, K. Lerman, and A. Galstyan, \"A Survey on Bias and Fairness in Machine Learning,\" arXiv:1908.09635v2 [cs.LG], Sep. 2019. Available: https://arxiv.org/abs/1908.09635\n",
    "\n",
    "[2] C.-H. Chiang and H.-y. Lee, \"Can Large Language Models Be an Alternative to Human Evaluation?\" in Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (ACL), Volume 1: Long Papers, pp. 15607–15631, July 2023. Available: https://www.aclweb.org/anthology/2023.acl-long.870\n",
    "\n",
    "[3] van der Lee, C., Gatt, A., van Miltenburg, E., & Krahmer, E. (2021). Human evaluation of automatically generated text: Current trends and best practice guidelines. Computer Speech &amp; Language, 67, 101151. doi:10.1016/j.csl.2020.101151\n",
    "\n",
    "[4] W.-L. Chiang, L. Zheng, Y. Sheng, A. N. Angelopoulos, T. Li, D. Li, B. Zhu, H. Zhang, M. I. Jordan, J. E. Gonzalez, and I. Stoica, \"Chatbot Arena: An Open Platform for Evaluating LLMs by Human Preference,\" arXiv:2403.04132v1 [cs.AI], Mar. 2024. Available: https://arxiv.org/abs/2403.04132\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
